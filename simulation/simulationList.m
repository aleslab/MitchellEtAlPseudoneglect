%% This file stores the simulation parameters used. 


%% Simulation 1: Null Hypothesis: 0 bias, 0 Variance
%The importance of simulating the null cannot be overstated!
%This is the only way to verify the statistical procedure is calibrated
%correctly.
% The 0 bias is easy to understand.  0 Cross participant variance and 0
% cross condition variance is wierder.  Since we're looking for a
% within-participant factor that -consistently- effects the measurement any
% cross-participant variance component that creates a common change within
% a participant, but across sessions/conditions -is- what we're looking
% for.
%This simulation should report about .05 experiments are significant (i.e.
%type 1 error). That will confirm that statisitcal procedures beign run
%have correrct type 1 error of 0.05 under the null hypothesis.

simOptions = {...
    'nTrialsPerSession', 90, ...
    'nSessions',         4,   ...
    'nParticipants',     24,  ...     
    'nConditions',       2,   ...       
    'nSimulations',     1000,  ...
    'trialRandFun',         @normrnd, ...
    'trialParam',          {0 .5;0 1},...
    'conditionRandFun',    @normrnd,...
    'conditionParam',      {0 0},... %<--- null hypothesis: No consistent condition effect
    'sessionRandFun',      @normrnd,...
    'sessionParam',        {0 2},...
    'participantRandFun',  @normrnd,...
    'participantParam',    {0 0},... %<--- null hypothesis: No overall bias and No consistent participant effect
    };

[resultsByCondition, resultsAllCondition] = simulateBias(simOptions{:});

%% Example Sim 1: Split variance between sessions
%Note: -Variances- are additive, standard deviations add by square root of sum of squares 
%In this sim let's split a standard deviation of 10 evenly across
%participants and sessions. 

simOptions = {...
    'nTrialsPerSession', 90, ...
    'nSessions',         4,   ...
    'nParticipants',     30,  ...     
    'nConditions',       2,   ...       
    'nSimulations',     100,  ...
    'trialRandFun',         @normrnd, ...
    'trialParam',          {0 0.5;0 1.2},...
    'conditionRandFun',    @normrnd,...
    'conditionParam',      {0 0},... %<Assume no difference between cond. 
    'sessionRandFun',      @normrnd,...
    'sessionParam',        {0 7},...
    'participantRandFun',  @normrnd,...
    'participantParam',    {5 7},...
    };

[resultsByCondition, resultsAllCondition] = simulateBias(simOptions{:});



%% Example 2: Using a loop to do multiple simulations

fixedOptions = {...
     'nTrialsPerSession', 90, ...
     'nSessions',         4,   ...
    'nParticipants',     24,  ...     
    'nConditions',       1,   ...       
    'nSimulations',     1000,  ...
    'trialRandFun',         @normrnd, ...
    'trialParam',          {0 0.5;0 1},...
    'conditionRandFun',    @normrnd,...
    'conditionParam',      {0 2},...
    'sessionRandFun',      @normrnd,...
    'sessionParam',        {0 2},...
    'participantRandFun',  @normrnd,...
    'participantParam',    {5 7},...
    };


conditionStdList = [0 .5 1 2 4];

for iCond = 1:length(conditionStdList)
    
    thisStd = conditionStdList(iCond);
    disp(['Running simulation for cross-condition standard deviation: ' num2str(thisStd)])
    changingOptions = { 'conditionParam', {0 thisStd }};
    
    simOptions = [ fixedOptions changingOptions ];
    
    
    [resultsByCondition, resultsAllCondition] = simulateBias(simOptions{:});
    
    
    
end



